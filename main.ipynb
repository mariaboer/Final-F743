{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import logging\n",
        "import os\n",
        "import threading\n",
        "\n",
        "\n",
        "import notebooks.Chunkfile_0 as loader  # noqa\n",
        "import notebooks.Preprocessing_1 as preproc  # noqa\n",
        "import notebooks.DataVisuals_2 as visuals\n",
        "import notebooks.K_Nearest_Neighbor_3 as KNN\n",
        "import notebooks.Principle_Component_Analysis_4 as PCA\n",
        "import notebooks.XGBoost_5 as XGB\n",
        "import notebooks.GridSearchCV_6 as GridSearch\n",
        "import notebooks.GradientBoostingRegressor_7 as GBR\n",
        "import notebooks.AdaBoosterRegressor_8 as ABR\n",
        "import notebooks.RandomForestRegressor_9 as RFR\n",
        "import notebooks.MLP_Regressor_10 as MLP\n",
        "\n",
        "def configure_logging(level=logging.INFO, log_path=None):\n",
        "    if log_path is None:\n",
        "        log_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'logs')\n",
        "    if not os.path.exists(log_path):\n",
        "        os.mkdir(log_path)\n",
        "\n",
        "    log_file = os.path.join(log_path, f\"{os.path.dirname(os.path.realpath(__file__)).split(os.sep)[-1]}.log\")\n",
        "    if level == logging.INFO or logging.NOTSET:\n",
        "        logging.basicConfig(\n",
        "            level=level,\n",
        "            format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "            handlers=[\n",
        "                logging.FileHandler(log_file),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "    elif level == logging.DEBUG or level == logging.ERROR:\n",
        "        logging.basicConfig(\n",
        "            level=level,\n",
        "            format=\"%(asctime)s %(filename)s function:%(funcName)s()\\t[%(levelname)s] %(message)s\",\n",
        "            handlers=[\n",
        "                logging.FileHandler(log_file),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "\n",
        "\n",
        "def str_or_none(value):\n",
        "    return value if value is None else str(value)\n",
        "\n",
        "\n",
        "def main():\n",
        "    rootpath = os.path.dirname(os.path.realpath(__file__))\n",
        "    # USED TO RUN without threading\n",
        "    # loader.main(rootpath)\n",
        "    # preproc.main(rootpath, 'Memory')\n",
        "    # visuals.main(rootpath, 'Memory')\n",
        "    # KNN.main(rootpath, 'Memory')\n",
        "    # PCA.main(rootpath, 'Memory')\n",
        "    # XGB.main(rootpath, 'Memory')\n",
        "    # GridSearch.main(rootpath, 'Memory')\n",
        "    # GBR.main(rootpath, 'Memory')\n",
        "    # ABR.main(rootpath, 'Memory')\n",
        "    # MLP.main(rootpath, 'Memory')\n",
        "    # RFR.main(rootpath, 'Memory')\n",
        "\n",
        "\n",
        "     loader.main(rootpath)\n",
        "     preproc.main(rootpath, 'Memory')\n",
        "\n",
        "    threads = []\n",
        "    active_threads = []\n",
        "    max_threads = 2  # Adjust this number to reduce the amount of memory usage\n",
        "\n",
        "    threads.append(threading.Thread(target=visuals.main, args=(rootpath, 'Memory')))\n",
        "    threads.append(threading.Thread(target=KNN.main, args=(rootpath, 'Memory')))\n",
        "    threads.append(threading.Thread(target=PCA.main, args=(rootpath, 'Memory')))\n",
        "    threads.append(threading.Thread(target=XGB.main, args=(rootpath, 'Memory')))\n",
        "    threads.append(threading.Thread(target=GridSearch.main, args=(rootpath, 'Memory')))\n",
        "    threads.append(threading.Thread(target=GBR.main, args=(rootpath, 'Memory')))\n",
        "    threads.append(threading.Thread(target=ABR.main, args=(rootpath, 'Memory')))\n",
        "    threads.append(threading.Thread(target=RFR.main, args=(rootpath, 'Memory')))\n",
        "    threads.append(threading.Thread(target=MLP.main, args=(rootpath, 'Memory')))\n",
        "    threads.append(threading.Thread(target=NN.main, args=(rootpath,'Memory')))\n",
        "\n",
        "    while len(threads) > 0:\n",
        "        if threading.active_count() < max_threads:\n",
        "            threads.pop().start()\n",
        "            logging.debug(f\"Thread started. Active threads: {threading.active_count()}\")\n",
        "            sleep(1)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        # Steps 1 and 2 in main is preprocessing and pickle files will be saved.\n",
        "        # This process takes up to 30 minutes to run and is highly recommended to be run only 1x.\n",
        "        # The pickle file is used for all subsequent steps\n",
        "        # The preprocessing step requires ~25GB of RAM.\n",
        "        # Please ensure you have enough RAM before running these steps.\n",
        "        # If you do not have enough RAM, please run the notebooks individually.\n",
        "        configure_logging(logging.INFO)\n",
        "        main()\n",
        "        print('All threads completed')\n",
        "    except KeyboardInterrupt:\n",
        "        print('Program terminated by user')\n",
        "        exit(-1)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        exit(-1)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}