{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766ef7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Bring in the appropriate packages\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6066c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create definition for working with date and time items\n",
    "def convert_duration(duration_str):\n",
    "    # Pattern for 'PT#H#M' and 'P#DT#H#M'\n",
    "    pattern = re.compile(r'P(?:(\\d+)D)?T(?:(\\d+)H)?(?:(\\d+)M)?')\n",
    "\n",
    "    match = pattern.match(duration_str)\n",
    "    if match:\n",
    "        days = int(match.group(1) or 0)\n",
    "        hours = int(match.group(2) or 0)\n",
    "        minutes = int(match.group(3) or 0)\n",
    "        total_minutes = days * 24 * 60 + hours * 60 + minutes\n",
    "        return total_minutes\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5638b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create split function for flights with more than one stop\n",
    "def split_columns(row, column_name):\n",
    "    values = row[column_name].split(\"||\")\n",
    "    return values + [0] * (4 - len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a1f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create translate functions where the PCA will take place\n",
    "\n",
    "df = pd.read_csv('Atlanta Prices.csv')\n",
    "\n",
    "# df.info()\n",
    "df.drop(['legId'],inplace=True,axis=1)\n",
    "##Drop LegID as this is not needed in the PCA as it is a unique identifier\n",
    "df = df.dropna()\n",
    "##Drop any row with NA. In our analysis there are no seats remaining in columns with NA values\n",
    "# df.info()\n",
    "## Convert 'searchDate' and 'flightDate' from object to datetime-type\n",
    "##df['searchDate'] = pd.to_datetime(df['searchDate'])\n",
    "##df['flightDate'] = pd.to_datetime(df['flightDate'])\n",
    "columns_to_process = [\n",
    "    'segmentsDepartureTimeEpochSeconds',\n",
    "    'segmentsDepartureTimeRaw',\n",
    "    'segmentsArrivalTimeEpochSeconds',\n",
    "    'segmentsArrivalTimeRaw',\n",
    "    'segmentsArrivalAirportCode',\n",
    "    'segmentsDepartureAirportCode',\n",
    "    'segmentsAirlineName',\n",
    "    'segmentsAirlineCode',\n",
    "    'segmentsEquipmentDescription',\n",
    "    'segmentsDurationInSeconds',\n",
    "    'segmentsDistance',\n",
    "    'segmentsCabinCode',\n",
    "]\n",
    "\n",
    "for column_name in columns_to_process:\n",
    "    new_columns = df.apply(lambda row: split_columns(row, column_name), axis=1, result_type='expand')\n",
    "    df[[f'{column_name}_1', f'{column_name}_2', f'{column_name}_3', f'{column_name}_4']] = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05cb9596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          segmentsDepartureTimeRaw_1  weeknum time_of_departure  \\\n",
      "0      2022-04-17T12:57:00.000-04:00       15           Mid-Day   \n",
      "1      2022-04-17T06:30:00.000-04:00       15           Morning   \n",
      "2      2022-04-17T11:35:00.000-04:00       15           Mid-Day   \n",
      "3      2022-04-17T13:59:00.000-04:00       15           Mid-Day   \n",
      "4      2022-04-17T09:59:00.000-04:00       15           Mid-Day   \n",
      "...                              ...      ...               ...   \n",
      "15998  2022-05-05T08:02:00.000-04:00       18           Mid-Day   \n",
      "15999  2022-05-05T09:00:00.000-04:00       18           Mid-Day   \n",
      "16000  2022-05-05T22:38:00.000-04:00       18             Night   \n",
      "16001  2022-05-05T10:00:00.000-04:00       18           Mid-Day   \n",
      "16002  2022-05-05T16:45:00.000-04:00       18             Night   \n",
      "\n",
      "      time_of_arrival  \n",
      "0             Mid-Day  \n",
      "1             Mid-Day  \n",
      "2             Mid-Day  \n",
      "3               Night  \n",
      "4             Mid-Day  \n",
      "...               ...  \n",
      "15998         Mid-Day  \n",
      "15999         Mid-Day  \n",
      "16000         Morning  \n",
      "16001         Mid-Day  \n",
      "16002           Night  \n",
      "\n",
      "[14303 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df['totalTravelDuration'] = df['travelDuration'].apply(lambda x: convert_duration(x))\n",
    "# df.head()\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == 1:\n",
    "        df.drop(col, inplace=True, axis=1)\n",
    "\n",
    "df['weeknum'] = pd.to_datetime(df['segmentsDepartureTimeRaw_1'], format='%Y-%m-%dT%H:%M:%S.%f%z').dt.isocalendar().week\n",
    "\n",
    "df['hour_of_flight']=df['segmentsDepartureTimeRaw_1'].str.split('T').str[1].str.split('.').str[0]\n",
    "df['departure_min'] = pd.to_datetime(df['hour_of_flight'], format='%H:%M:%S').dt.hour * 60 + pd.to_datetime(df['hour_of_flight'], format='%H:%M:%S').dt.minute\n",
    "df['time_of_departure'] = np.where(df['departure_min'] <= (8 * 60), \"Morning\", np.where(df['departure_min'] <= (16 * 60), \"Mid-Day\", \"Night\"))\n",
    "\n",
    "df['last_arrival_time']=df['segmentsArrivalTimeRaw'].str[-29:]\n",
    "df['last_arrival_time']=df['last_arrival_time'].str.split('T').str[1].str.split('.').str[0]\n",
    "df['last_arrival_time']=pd.to_datetime(df['last_arrival_time'], format='%H:%M:%S').dt.hour * 60 + pd.to_datetime(df['last_arrival_time'], format='%H:%M:%S').dt.minute\n",
    "df['time_of_arrival'] = np.where(df['last_arrival_time'] <= (8 * 60), \"Morning\", np.where(df['last_arrival_time'] <= (16 * 60), \"Mid-Day\", \"Night\"))\n",
    "\n",
    "\n",
    "print(df[['segmentsDepartureTimeRaw_1','weeknum','time_of_departure','time_of_arrival']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02b3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_count = ['segmentsAirlineName_1', 'segmentsAirlineName_2', 'segmentsAirlineName_3', 'segmentsAirlineName_4']\n",
    "df['no_airlines'] = df[columns_to_count].apply(lambda row: len(set(filter(lambda x: x != 0, row))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f86ebe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "15998    2\n",
      "15999    2\n",
      "16000    2\n",
      "16001    1\n",
      "16002    1\n",
      "Name: no_layovers, Length: 14303, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "columns_to_count = ['segmentsArrivalAirportCode_1', 'segmentsArrivalAirportCode_2', 'segmentsArrivalAirportCode_3', 'segmentsArrivalAirportCode_4']\n",
    "df['no_layovers'] = df[columns_to_count].apply(lambda row: len(set(filter(lambda x: x != 0, row))), axis=1)\n",
    "print(df['no_layovers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "809ddc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>baseFare</th>\n",
       "      <th>seatsRemaining</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "      <th>totalTravelDuration</th>\n",
       "      <th>weeknum</th>\n",
       "      <th>time_of_departure</th>\n",
       "      <th>time_of_arrival</th>\n",
       "      <th>no_airlines</th>\n",
       "      <th>no_layovers</th>\n",
       "      <th>segmentsCabinCode_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOS</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>217.67</td>\n",
       "      <td>9.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>149</td>\n",
       "      <td>15</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOS</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>217.67</td>\n",
       "      <td>4.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>217.67</td>\n",
       "      <td>9.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>217.67</td>\n",
       "      <td>8.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>152</td>\n",
       "      <td>15</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>Night</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOS</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>217.67</td>\n",
       "      <td>9.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>154</td>\n",
       "      <td>15</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  destinationAirport  isBasicEconomy  isNonStop  baseFare  seatsRemaining  \\\n",
       "0                BOS           False       True    217.67             9.0   \n",
       "1                BOS           False       True    217.67             4.0   \n",
       "2                BOS           False       True    217.67             9.0   \n",
       "3                BOS           False       True    217.67             8.0   \n",
       "4                BOS           False       True    217.67             9.0   \n",
       "\n",
       "   totalTravelDistance  totalTravelDuration  weeknum time_of_departure  \\\n",
       "0                947.0                  149       15           Mid-Day   \n",
       "1                947.0                  150       15           Morning   \n",
       "2                947.0                  150       15           Mid-Day   \n",
       "3                947.0                  152       15           Mid-Day   \n",
       "4                947.0                  154       15           Mid-Day   \n",
       "\n",
       "  time_of_arrival  no_airlines  no_layovers segmentsCabinCode_1  \n",
       "0         Mid-Day            1            1               coach  \n",
       "1         Mid-Day            1            1               coach  \n",
       "2         Mid-Day            1            1               coach  \n",
       "3           Night            1            1               coach  \n",
       "4         Mid-Day            1            1               coach  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = ['destinationAirport','isBasicEconomy', 'isNonStop', 'baseFare', 'seatsRemaining', \n",
    "                   'totalTravelDistance', 'totalTravelDuration','weeknum', \n",
    "                   'time_of_departure', 'time_of_arrival', 'no_airlines', 'no_layovers'\n",
    "                  ,'segmentsCabinCode_1']\n",
    "\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c1077ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14303 entries, 0 to 16002\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   destinationAirport   14303 non-null  object \n",
      " 1   isBasicEconomy       14303 non-null  bool   \n",
      " 2   isNonStop            14303 non-null  bool   \n",
      " 3   baseFare             14303 non-null  float64\n",
      " 4   seatsRemaining       14303 non-null  float64\n",
      " 5   totalTravelDistance  14303 non-null  float64\n",
      " 6   totalTravelDuration  14303 non-null  int64  \n",
      " 7   weeknum              14303 non-null  UInt32 \n",
      " 8   time_of_departure    14303 non-null  object \n",
      " 9   time_of_arrival      14303 non-null  object \n",
      " 10  no_airlines          14303 non-null  int64  \n",
      " 11  no_layovers          14303 non-null  int64  \n",
      " 12  segmentsCabinCode_1  14303 non-null  object \n",
      "dtypes: UInt32(1), bool(2), float64(3), int64(3), object(4)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae79b0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 9714.953207683384\n",
      "R-squared: 0.6404033480062912\n"
     ]
    }
   ],
   "source": [
    "#Import pacakges necessary for the creation of a pipeline that encodes, then scales the numerical data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('baseFare', axis=1)\n",
    "y = df['baseFare']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for encoding and scaling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the XGBoost Regressor model\n",
    "model = XGBRegressor()\n",
    "\n",
    "# Create a pipeline with encoding and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56b3d051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_child_weight': 1, 'model__n_estimators': 300, 'model__subsample': 0.8}\n",
      "Mean Squared Error: 9670.933080739997\n",
      "R-squared: 0.6420327423976775\n"
     ]
    }
   ],
   "source": [
    "#This algorithm uses gridsearch to identify the optimal hyperparameters \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('baseFare', axis=1)\n",
    "y = df['baseFare']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for encoding and scaling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the XGBoost Regressor model\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "# Create a pipeline with encoding and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', xgb_model)])\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__min_child_weight': [1, 3, 5],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Best Hyperparameters: {grid_search.best_params_}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r_squared}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe1edf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_child_weight': 1, 'model__n_estimators': 300, 'model__subsample': 0.8}\n",
      "Mean Squared Error: 9315.684684960568\n",
      "R-squared: 0.6612753725399783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"model__colsample_bytree\", \"model__learning_rate\", \"model__max_depth\", \"model__min_child_weight\", \"model__n_estimators\", \"model__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Once hyperparameters are identified we run the algorithm again with said parameters and increase the R-squared slightly\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('baseFare', axis=1)\n",
    "y = df['baseFare']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for encoding and scaling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Use the best hyperparameters from GridSearchCV\n",
    "best_hyperparameters = {'model__colsample_bytree': 0.8,\n",
    "                        'model__learning_rate': 0.1,\n",
    "                        'model__max_depth': 7,\n",
    "                        'model__min_child_weight': 1,\n",
    "                        'model__n_estimators': 300,\n",
    "                        'model__subsample': 0.8}\n",
    "\n",
    "# Create the XGBoost Regressor model with the best hyperparameters\n",
    "xgb_model = XGBRegressor(**best_hyperparameters)\n",
    "\n",
    "# Create a pipeline with encoding and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', xgb_model)])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Best Hyperparameters: {best_hyperparameters}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58e20c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 13082.112062334896\n",
      "R-squared: 0.5157687743774608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor  # Import GradientBoostingRegressor\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('baseFare', axis=1)\n",
    "y = df['baseFare']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for encoding and scaling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the Gradient Boosting Regressor model\n",
    "model = GradientBoostingRegressor()  # Use GradientBoostingRegressor instead of XGBRegressor\n",
    "\n",
    "# Create a pipeline with encoding and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d8c202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 34343.87792251694\n",
      "R-squared: -0.2712303655410706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor  # Import AdaBoostRegressor\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('baseFare', axis=1)\n",
    "y = df['baseFare']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for encoding and scaling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the AdaBoost Regressor model\n",
    "model = AdaBoostRegressor()  # Use AdaBoostRegressor instead of XGBRegressor\n",
    "\n",
    "# Create a pipeline with encoding and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r_squared}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c111e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 10087.69064686297\n",
      "R-squared: 0.6266065615126947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor  # Import RandomForestRegressor\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('baseFare', axis=1)\n",
    "y = df['baseFare']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for encoding and scaling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the Random Forest Regressor model\n",
    "model = RandomForestRegressor()  # Use RandomForestRegressor instead of AdaBoostRegressor\n",
    "\n",
    "# Create a pipeline with encoding and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r_squared}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be249799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 13318.532677148785\n",
      "R-squared: 0.5070177222898264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor  # Import MLPRegressor\n",
    "\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('baseFare', axis=1)\n",
    "y = df['baseFare']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for encoding and scaling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_columns)  # Use drop='first' to avoid dummy variable trap\n",
    "    ])\n",
    "\n",
    "# Create the MLP Regressor model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=500)  # Example: one hidden layer with 100 neurons\n",
    "\n",
    "# Create a pipeline with encoding and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', mlp_model)])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r_squared}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed39287c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
